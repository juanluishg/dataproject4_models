{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "sentiment-pose(v2).ipynb copia",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lm7AI55Bory"
      },
      "source": [
        "#MAKE DETECTIONS WITH MODEL\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7bOPumMBory"
      },
      "source": [
        "with open('body_language.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkgDkzF7Bory",
        "outputId": "ade8e77f-c651-4766-b2eb-7d67296d55d1"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('randomforestclassifier', RandomForestClassifier())])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBDaMaEVBorz",
        "outputId": "fe46c448-f10e-4fc9-c8c7-946f6d6e88fd"
      },
      "source": [
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# Initiate holistic model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "    \n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # Recolor Feed\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False        \n",
        "        \n",
        "        # Make Detections\n",
        "        results = holistic.process(image)\n",
        "        # print(results.face_landmarks)\n",
        "        \n",
        "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
        "        \n",
        "        # Recolor image back to BGR for rendering\n",
        "        image.flags.writeable = True   \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        # 1. Draw face landmarks\n",
        "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
        "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                                 )\n",
        "        \n",
        "        # 2. Right hand\n",
        "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 3. Left Hand\n",
        "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "\n",
        "        # 4. Pose Detections\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
        "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                                 )\n",
        "        # Export coordinates\n",
        "        try:\n",
        "            # Extract Pose landmarks\n",
        "            pose = results.pose_landmarks.landmark\n",
        "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
        "            \n",
        "            # Extract Face landmarks\n",
        "            face = results.face_landmarks.landmark\n",
        "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
        "            \n",
        "            # Concate rows\n",
        "            row = pose_row+face_row\n",
        "            \n",
        "#             # Append class name \n",
        "#             row.insert(0, class_name)\n",
        "            \n",
        "#             # Export to CSV\n",
        "#             with open('coords.csv', mode='a', newline='') as f:\n",
        "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "#                 csv_writer.writerow(row) \n",
        "\n",
        "            # Make Detections\n",
        "            X = pd.DataFrame([row])\n",
        "            body_language_class = model.predict(X)[0]\n",
        "            body_language_prob = model.predict_proba(X)[0]\n",
        "            print(body_language_class, body_language_prob)\n",
        "            \n",
        "            # Grab ear coords\n",
        "            coords = tuple(np.multiply(\n",
        "                            np.array(\n",
        "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
        "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
        "                        , [640,480]).astype(int))\n",
        "            \n",
        "            cv2.rectangle(image, \n",
        "                          (coords[0], coords[1]+5), \n",
        "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
        "                          (245, 117, 16), -1)\n",
        "            cv2.putText(image, body_language_class, coords, \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            \n",
        "            # Get status box\n",
        "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
        "            \n",
        "            # Display Class\n",
        "            cv2.putText(image, 'CLASS'\n",
        "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "            cv2.putText(image, body_language_class.split(' ')[0]\n",
        "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            \n",
        "            # Display Probability\n",
        "            cv2.putText(image, 'PROB'\n",
        "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
        "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "                        \n",
        "        cv2.imshow('Raw Webcam Feed', image)\n",
        "\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Happy [0.31 0.54 0.04 0.11]\n",
            "Happy [0.31 0.53 0.04 0.12]\n",
            "Happy [0.26 0.58 0.04 0.12]\n",
            "Happy [0.22 0.63 0.02 0.13]\n",
            "Happy [0.22 0.61 0.04 0.13]\n",
            "Happy [0.21 0.61 0.05 0.13]\n",
            "Happy [0.2  0.64 0.03 0.13]\n",
            "Happy [0.17 0.72 0.01 0.1 ]\n",
            "Happy [0.23 0.64 0.02 0.11]\n",
            "Happy [0.18 0.73 0.   0.09]\n",
            "Happy [0.13 0.8  0.   0.07]\n",
            "Happy [0.12 0.8  0.   0.08]\n",
            "Happy [0.11 0.81 0.   0.08]\n",
            "Happy [0.14 0.7  0.03 0.13]\n",
            "Happy [0.17 0.65 0.03 0.15]\n",
            "Happy [0.16 0.63 0.05 0.16]\n",
            "Happy [0.15 0.65 0.05 0.15]\n",
            "Happy [0.13 0.67 0.08 0.12]\n",
            "Happy [0.17 0.64 0.09 0.1 ]\n",
            "Happy [0.2  0.62 0.08 0.1 ]\n",
            "Happy [0.2  0.64 0.07 0.09]\n",
            "Happy [0.21 0.61 0.07 0.11]\n",
            "Happy [0.2  0.62 0.07 0.11]\n",
            "Happy [0.22 0.62 0.08 0.08]\n",
            "Happy [0.2  0.66 0.06 0.08]\n",
            "Happy [0.22 0.65 0.05 0.08]\n",
            "Happy [0.21 0.65 0.05 0.09]\n",
            "Happy [0.21 0.65 0.05 0.09]\n",
            "Happy [0.21 0.64 0.06 0.09]\n",
            "Happy [0.23 0.62 0.06 0.09]\n",
            "Happy [0.25 0.58 0.1  0.07]\n",
            "Happy [0.25 0.58 0.1  0.07]\n",
            "Disgust [0.4  0.38 0.13 0.09]\n",
            "Happy [0.34 0.43 0.12 0.11]\n",
            "Happy [0.35 0.42 0.1  0.13]\n",
            "Happy [0.29 0.57 0.05 0.09]\n",
            "Happy [0.26 0.62 0.06 0.06]\n",
            "Happy [0.27 0.61 0.06 0.06]\n",
            "Happy [0.27 0.58 0.08 0.07]\n",
            "Happy [0.34 0.42 0.07 0.17]\n",
            "Happy [0.25 0.6  0.06 0.09]\n",
            "Happy [0.22 0.64 0.06 0.08]\n",
            "Happy [0.24 0.61 0.09 0.06]\n",
            "Happy [0.23 0.62 0.09 0.06]\n",
            "Happy [0.25 0.56 0.12 0.07]\n",
            "Happy [0.23 0.6  0.11 0.06]\n",
            "Happy [0.22 0.59 0.13 0.06]\n",
            "Happy [0.23 0.58 0.12 0.07]\n",
            "Happy [0.24 0.59 0.12 0.05]\n",
            "Happy [0.22 0.58 0.13 0.07]\n",
            "Happy [0.22 0.61 0.1  0.07]\n",
            "Happy [0.28 0.58 0.09 0.05]\n",
            "Happy [0.37 0.43 0.06 0.14]\n",
            "Happy [0.4  0.45 0.06 0.09]\n",
            "Disgust [0.45 0.4  0.07 0.08]\n",
            "Disgust [0.44 0.41 0.06 0.09]\n",
            "Disgust [0.48 0.35 0.1  0.07]\n",
            "Disgust [0.47 0.39 0.09 0.05]\n",
            "Disgust [0.43 0.38 0.12 0.07]\n",
            "Disgust [0.42 0.39 0.11 0.08]\n",
            "Happy [0.34 0.5  0.07 0.09]\n",
            "Happy [0.29 0.52 0.13 0.06]\n",
            "Happy [0.3  0.5  0.11 0.09]\n",
            "Happy [0.29 0.48 0.14 0.09]\n",
            "Happy [0.27 0.5  0.16 0.07]\n",
            "Happy [0.3  0.45 0.17 0.08]\n",
            "Happy [0.25 0.48 0.16 0.11]\n",
            "Happy [0.28 0.41 0.2  0.11]\n",
            "Happy [0.32 0.37 0.24 0.07]\n",
            "Disgust [0.36 0.31 0.25 0.08]\n",
            "Disgust [0.35 0.29 0.29 0.07]\n",
            "Disgust [0.33 0.29 0.3  0.08]\n",
            "Disgust [0.33 0.28 0.31 0.08]\n",
            "Happy [0.32 0.34 0.26 0.08]\n",
            "Happy [0.31 0.36 0.25 0.08]\n",
            "Happy [0.3  0.4  0.23 0.07]\n",
            "Happy [0.3  0.35 0.26 0.09]\n",
            "Happy [0.29 0.36 0.26 0.09]\n",
            "Happy [0.31 0.35 0.26 0.08]\n",
            "Happy [0.29 0.38 0.26 0.07]\n",
            "Happy [0.28 0.37 0.27 0.08]\n",
            "Happy [0.3  0.36 0.25 0.09]\n",
            "Happy [0.29 0.36 0.23 0.12]\n",
            "Happy [0.31 0.36 0.23 0.1 ]\n",
            "Happy [0.3  0.35 0.26 0.09]\n",
            "Happy [0.31 0.35 0.24 0.1 ]\n",
            "Happy [0.28 0.35 0.26 0.11]\n",
            "Happy [0.29 0.34 0.25 0.12]\n",
            "Happy [0.27 0.37 0.22 0.14]\n",
            "Happy [0.27 0.37 0.23 0.13]\n",
            "Happy [0.28 0.38 0.23 0.11]\n",
            "Happy [0.3  0.36 0.23 0.11]\n",
            "Happy [0.09 0.78 0.07 0.06]\n",
            "Happy [0.08 0.73 0.05 0.14]\n",
            "Happy [0.1  0.62 0.06 0.22]\n",
            "Happy [0.1  0.67 0.05 0.18]\n",
            "Happy [0.12 0.67 0.06 0.15]\n",
            "Happy [0.1  0.77 0.01 0.12]\n",
            "Happy [0.21 0.41 0.11 0.27]\n",
            "Happy [0.25 0.29 0.17 0.29]\n",
            "Happy [0.29 0.31 0.16 0.24]\n",
            "Disgust [0.37 0.18 0.16 0.29]\n",
            "Surprise [0.24 0.24 0.15 0.37]\n",
            "Sad [0.17 0.06 0.39 0.38]\n",
            "Disgust [0.41 0.23 0.29 0.07]\n",
            "Sad [0.24 0.16 0.48 0.12]\n",
            "Sad [0.18 0.13 0.57 0.12]\n",
            "Sad [0.17 0.12 0.57 0.14]\n",
            "Sad [0.23 0.19 0.38 0.2 ]\n",
            "Surprise [0.16 0.15 0.32 0.37]\n",
            "Sad [0.35 0.15 0.36 0.14]\n",
            "Disgust [0.35 0.17 0.34 0.14]\n",
            "Disgust [0.36 0.14 0.36 0.14]\n",
            "Disgust [0.36 0.14 0.36 0.14]\n",
            "Sad [0.33 0.14 0.38 0.15]\n",
            "Sad [0.33 0.14 0.37 0.16]\n",
            "Sad [0.35 0.12 0.38 0.15]\n",
            "Sad [0.37 0.11 0.38 0.14]\n",
            "Sad [0.36 0.12 0.41 0.11]\n",
            "Sad [0.32 0.11 0.38 0.19]\n",
            "Sad [0.31 0.11 0.36 0.22]\n",
            "Sad [0.32 0.12 0.41 0.15]\n",
            "Surprise [0.22 0.24 0.24 0.3 ]\n",
            "Surprise [0.32 0.25 0.05 0.38]\n",
            "Surprise [0.26 0.27 0.06 0.41]\n",
            "Surprise [0.26 0.33 0.07 0.34]\n",
            "Surprise [0.29 0.27 0.14 0.3 ]\n",
            "Disgust [0.53 0.24 0.07 0.16]\n",
            "Disgust [0.44 0.24 0.16 0.16]\n",
            "Disgust [0.49 0.27 0.1  0.14]\n",
            "Disgust [0.49 0.23 0.1  0.18]\n",
            "Disgust [0.48 0.21 0.12 0.19]\n",
            "Disgust [0.54 0.17 0.11 0.18]\n",
            "Disgust [0.55 0.18 0.1  0.17]\n",
            "Disgust [0.56 0.19 0.1  0.15]\n",
            "Disgust [0.55 0.22 0.1  0.13]\n",
            "Disgust [0.54 0.19 0.12 0.15]\n",
            "Sad [0.2  0.1  0.67 0.03]\n",
            "Sad [0.   0.04 0.95 0.01]\n",
            "Sad [0.01 0.07 0.91 0.01]\n",
            "Sad [0.01 0.07 0.91 0.01]\n",
            "Sad [0.01 0.04 0.93 0.02]\n",
            "Sad [0.01 0.04 0.93 0.02]\n",
            "Sad [0.01 0.04 0.93 0.02]\n",
            "Sad [0.01 0.   0.97 0.02]\n",
            "Sad [0.01 0.01 0.96 0.02]\n",
            "Sad [0.01 0.01 0.96 0.02]\n",
            "Sad [0.01 0.01 0.96 0.02]\n",
            "Sad [0.01 0.01 0.97 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.97 0.02]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.01 0.   0.98 0.01]\n",
            "Sad [0.02 0.02 0.94 0.02]\n",
            "Sad [0.02 0.01 0.93 0.04]\n",
            "Sad [0.   0.01 0.97 0.02]\n",
            "Sad [0.   0.01 0.97 0.02]\n",
            "Sad [0.01 0.01 0.96 0.02]\n",
            "Sad [0.01 0.   0.97 0.02]\n",
            "Sad [0.01 0.01 0.96 0.02]\n",
            "Sad [0.   0.01 0.97 0.02]\n",
            "Sad [0.   0.01 0.97 0.02]\n",
            "Sad [0. 0. 1. 0.]\n",
            "Sad [0.   0.03 0.97 0.  ]\n",
            "Sad [0.   0.04 0.96 0.  ]\n",
            "Sad [0.   0.04 0.96 0.  ]\n",
            "Sad [0.01 0.08 0.91 0.  ]\n",
            "Sad [0.   0.08 0.92 0.  ]\n",
            "Sad [0.01 0.06 0.93 0.  ]\n",
            "Sad [0.01 0.07 0.92 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.06 0.1  0.77 0.07]\n",
            "Sad [0.07 0.09 0.77 0.07]\n",
            "Sad [0.07 0.08 0.76 0.09]\n",
            "Sad [0.05 0.07 0.82 0.06]\n",
            "Sad [0.01 0.04 0.91 0.04]\n",
            "Sad [0.01 0.04 0.93 0.02]\n",
            "Sad [0.01 0.08 0.89 0.02]\n",
            "Sad [0.03 0.1  0.84 0.03]\n",
            "Sad [0.02 0.15 0.81 0.02]\n",
            "Sad [0.02 0.11 0.85 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.03 0.94 0.02]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.   0.99 0.  ]\n",
            "Sad [0.01 0.03 0.96 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.01 0.06 0.93 0.  ]\n",
            "Sad [0.01 0.06 0.93 0.  ]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.07 0.9  0.02]\n",
            "Sad [0.01 0.07 0.9  0.02]\n",
            "Sad [0.01 0.07 0.9  0.02]\n",
            "Sad [0.01 0.04 0.93 0.02]\n",
            "Sad [0.01 0.03 0.96 0.  ]\n",
            "Sad [0.01 0.04 0.95 0.  ]\n",
            "Sad [0.01 0.06 0.91 0.02]\n",
            "Sad [0.01 0.06 0.91 0.02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84l2VAHSBor2",
        "outputId": "0c7868ea-d6ab-418f-ec58-f464eaa2fec5"
      },
      "source": [
        "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
        "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(428, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9rZMljBor3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}